{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 21:37:17.348531: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-06 21:37:17.355679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741315037.363995  567930 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741315037.366473  567930 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 21:37:17.375514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import deque\n",
    "import itertools\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "class AnaquelEnv:\n",
    "    def __init__(self, df, zones=9, anaqueles_per_zone=4, rows=3, cols=7):\n",
    "        self.df = df.copy()\n",
    "        self.df_iterations = df.copy()\n",
    "        self.zones = zones\n",
    "        self.anaqueles_per_zone = anaqueles_per_zone\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        # Matrix of weights (higher values indicate higher cost to place an item)\n",
    "        self.weight_matrix = np.array([\n",
    "            [5.5, 4.7, 3.5, 3.0, 2.0, 1.3, 1.0, 1.0, 1.3, 2.0, 3.0, 3.5, 4.7, 5.5, 5.5, 4.7, 3.5, 3.0, 2.0, 1.3, 1.0, 1.0, 1.3, 2.0, 3.0, 3.5, 4.7, 5.5, 5.5, 4.7, 3.5, 3.0, 2.0, 1.3, 1.0, 1.0, 1.3, 2.0, 3.0, 3.5, 4.7, 5.5],\n",
    "            [5.0, 4.3, 3.0, 2.7, 1.6, 1.0, 0.7, 0.7, 1.0, 1.6, 2.7, 3.0, 4.3, 5.0, 5.0, 4.3, 3.0, 2.7, 1.6, 1.0, 0.7, 0.7, 1.0, 1.6, 2.7, 3.0, 4.3, 5.0, 5.0, 4.3, 3.0, 2.7, 1.6, 1.0, 0.7, 0.7, 1.0, 1.6, 2.7, 3.0, 4.3, 5.0],\n",
    "            [4.3, 3.6, 2.5, 2.0, 1.3, 0.7, 0.5, 0.5, 0.7, 1.3, 2.0, 2.5, 3.6, 4.3, 4.3, 3.6, 2.5, 2.0, 1.3, 0.7, 0.5, 0.5, 0.7, 1.3, 2.0, 2.5, 3.6, 4.3, 4.3, 3.6, 2.5, 2.0, 1.3, 0.7, 0.5, 0.5, 0.7, 1.3, 2.0, 2.5, 3.6, 4.3],\n",
    "            [9.0, 7.7, 6.5, 5.5, 5.0, 4.3, 4.0, 4.0, 4.3, 5.0, 5.5, 6.5, 7.7, 9.0, 9.0, 7.7, 6.5, 5.5, 5.0, 4.3, 4.0, 4.0, 4.3, 5.0, 5.5, 6.5, 7.7, 9.0, 9.0, 7.7, 6.5, 5.5, 5.0, 4.3, 4.0, 4.0, 4.3, 5.0, 5.5, 6.5, 7.7, 9.0],\n",
    "            [9.8, 8.5, 7.0, 6.0, 5.5, 4.7, 4.3, 4.3, 4.7, 5.5, 6.0, 7.0, 8.5, 9.8, 9.8, 8.5, 7.0, 6.0, 5.5, 4.7, 4.3, 4.3, 4.7, 5.5, 6.0, 7.0, 8.5, 9.8, 9.8, 8.5, 7.0, 6.0, 5.5, 4.7, 4.3, 4.3, 4.7, 5.5, 6.0, 7.0, 8.5, 9.8],\n",
    "            [10.5, 9.0, 7.7, 6.5, 6.0, 5.0, 4.7, 4.7, 5.0, 6.0, 6.5, 7.7, 9.0, 10.5, 10.5, 9.0, 7.7, 6.5, 6.0, 5.0, 4.7, 4.7, 5.0, 6.0, 6.5, 7.7, 9.0, 10.5, 10.5, 9.0, 7.7, 6.5, 6.0, 5.0, 4.7, 4.7, 5.0, 6.0, 6.5, 7.7, 9.0, 10.5]\n",
    "        ])\n",
    "\n",
    "        self.avail_matrix = np.zeros(self.weight_matrix.shape)\n",
    "        self.products_id = np.zeros(self.weight_matrix.shape)\n",
    "        self.products_id.fill(-1)\n",
    "        \n",
    "        # Mapping product IDs to indexes for one-hot encoding\n",
    "        unique_products = df['PRODUCTO'].unique()\n",
    "        self.product_id_to_index = {pid: idx for idx, pid in enumerate(unique_products)}\n",
    "        self.num_products = len(unique_products)\n",
    "\n",
    "        # State representations\n",
    "        self.state_quantities = np.zeros(self.weight_matrix.shape)  \n",
    "        \n",
    "        self.action_space = zones * anaqueles_per_zone * rows * cols  # Total possible placements\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment for new episode\"\"\"\n",
    "        self.df_iterations = self.df.copy()\n",
    "        self.state_quantities.fill(0)\n",
    "        self.avail_matrix.fill(0)\n",
    "        self.products_id.fill(-1)\n",
    "        return self.state_quantities, self.products_id\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Perform an action and return next state, reward, and done flag\"\"\"\n",
    "        item = self.df_iterations.sample()\n",
    "        product_id = item['PRODUCTO'].values[0]\n",
    "        quantity = item['UNDESTIMADAS'].values[0]\n",
    "\n",
    "        if product_id not in self.product_id_to_index:\n",
    "            raise ValueError(f\"Product ID {product_id} not found in mapping\")\n",
    "\n",
    "        zone, anaquel, row, col = action\n",
    "\n",
    "        if self.avail_matrix[row, col] == -1:  # If cell is empty\n",
    "            self.products_id[row, col] = product_id\n",
    "            self.state_quantities[row, col] = quantity\n",
    "            self.avail_matrix[row, col] = 1\n",
    "            self.df_iterations = self.df_iterations[self.df_iterations['PRODUCTO'] != product_id]\n",
    "\n",
    "        reward = self.compute_reward()\n",
    "        done = self.is_done()\n",
    "\n",
    "        return self.state_quantities, self.avail_matrix, reward, done\n",
    "\n",
    "\n",
    "    def compute_reward(self, row, col):\n",
    "        \"\"\"Reward function: balance zones, prioritize high-demand items in front\"\"\"\n",
    "        if self.avail_matrix[row, col] == -1:\n",
    "            return -5000\n",
    "        return self.state_quantities[row, col] * self.weight_matrix[row, col]\n",
    "\n",
    "    def is_done(self):\n",
    "        return np.all(self.df_iterations.empty)  # Done when all cells are filled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "WARNING *** file size (65174245) not 512 + multiple of sector size (512)\n",
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n"
     ]
    }
   ],
   "source": [
    "file_path = 'productos_anaquel.xls'\n",
    "df_ = []\n",
    "i = 1\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.FileHandler('log.txt')\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.info('Reading file...')\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        df_.append(pd.read_excel(file_path, sheet_name=f\"Sheet {i}\"))\n",
    "        i += 1\n",
    "except:\n",
    "    pass\n",
    "\n",
    "df_ = pd.concat(df_, ignore_index=True)\n",
    "df = df_[df_['ANAQUEL'].str.startswith('C', na=False)]\n",
    "df = df[df['CAMPA'] == 201416]\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateProcessor:\n",
    "    def __init__(self, env):\n",
    "        self.num_products = env.num_products\n",
    "\n",
    "    def process(self, state_quantities, state_products_onehot):\n",
    "        # Flatten and concatenate both matrices\n",
    "        state = np.concatenate((state_quantities.flatten(), state_products_onehot.flatten()))\n",
    "        return tf.convert_to_tensor(state, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.fc3 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.fc4 = tf.keras.layers.Dense(output_dim, activation=None)  # No activation, raw Q-values\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(estimator, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "\n",
    "    Args:\n",
    "        estimator: A Q-Network that returns Q-values for a given state.\n",
    "        nA: Number of actions in the environment.\n",
    "\n",
    "    Returns:\n",
    "        A function that takes (sess, observation, epsilon) and returns\n",
    "        probabilities for each action as a numpy array of length nA.\n",
    "    \"\"\"\n",
    "    def policy_fn(sess, observation, epsilon):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA  # Uniform exploration probability\n",
    "        q_values = estimator(tf.expand_dims(observation, axis=0))[0].numpy()  # Get Q-values\n",
    "        best_action = np.argmax(q_values)  # Choose best action\n",
    "        A[best_action] += (1.0 - epsilon)  # Favor best action\n",
    "        return A\n",
    "    return policy_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target_network(q_network, target_q_network):\n",
    "    target_q_network.set_weights(q_network.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_q_learning(sess,\n",
    "                    env: AnaquelEnv,\n",
    "                    q_estimator: QNetwork,\n",
    "                    target_estimator: QNetwork,\n",
    "                    state_processor: StateProcessor,\n",
    "                    num_episodes,\n",
    "                    experiment_dir,\n",
    "                    replay_memory_size=5000,\n",
    "                    replay_memory_init_size=1000,\n",
    "                    update_target_estimator_every=500,\n",
    "                    discount_factor=0.99,\n",
    "                    epsilon_start=1.0,\n",
    "                    epsilon_end=0.1,\n",
    "                    epsilon_decay_steps=50000,\n",
    "                    batch_size=32):\n",
    "\n",
    "    Transition = namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    replay_memory = deque(maxlen=replay_memory_size)\n",
    "    rewards_list = []\n",
    "\n",
    "    # Create directories for saving models\n",
    "    checkpoint_dir = os.path.join(experiment_dir, \"checkpoints\")\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, \"model.weights.h5\")\n",
    "\n",
    "    # Create epsilon decay schedule\n",
    "    epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)\n",
    "    print(epsilons)\n",
    "\n",
    "    # Define ε-greedy policy\n",
    "    policy = make_epsilon_greedy_policy(q_estimator, env.action_space)\n",
    "\n",
    "    # Populate replay memory with initial random experience\n",
    "    print(\"Populating replay memory...\")\n",
    "    state_quantities, state_products_onehot = env.reset()\n",
    "    # to be understand\n",
    "    state = state_processor.process(state_quantities, state_products_onehot)\n",
    "\n",
    "    for i in range(replay_memory_init_size):\n",
    "        action_probs = policy(sess, state, epsilons[min(i, epsilon_decay_steps-1)])\n",
    "        action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
    "        row, col = np.unravel_index(action, (env.rows, env.cols))\n",
    "\n",
    "        next_state_quantities, next_state_products_onehot, reward, done = env.step((row, col))\n",
    "        next_state = state_processor.process(next_state_quantities, next_state_products_onehot)\n",
    "\n",
    "        replay_memory.append(Transition(state, action, reward, next_state, done))\n",
    "\n",
    "        if done:\n",
    "            state_quantities, state_products_onehot = env.reset()\n",
    "            state = state_processor.process(state_quantities, state_products_onehot)\n",
    "        else:\n",
    "            state = next_state\n",
    "\n",
    "    print(\"Replay memory initialized.\")\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state_quantities, state_products_onehot = env.reset()\n",
    "        state = state_processor.process(state_quantities, state_products_onehot)\n",
    "\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "\n",
    "        while not done:\n",
    "            epsilon = epsilons[min(step_count, epsilon_decay_steps - 1)]\n",
    "            action_probs = policy(sess, state, epsilon)\n",
    "            action = np.random.choice(np.arange(len(action_probs)), p=action_probs)\n",
    "            row, col = np.unravel_index(action, (env.rows, env.cols))\n",
    "\n",
    "            next_state_quantities, next_state_products_onehot, reward, done = env.step((row, col))\n",
    "            next_state = state_processor.process(next_state_quantities, next_state_products_onehot)\n",
    "\n",
    "            replay_memory.append(Transition(state, action, reward, next_state, done))\n",
    "\n",
    "            if len(replay_memory) >= batch_size:\n",
    "                batch = random.sample(replay_memory, batch_size)\n",
    "                states, actions, rewards, next_states, dones = zip(*batch)\n",
    "\n",
    "                states = tf.convert_to_tensor(np.array(states), dtype=tf.float32)\n",
    "                actions = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
    "                rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "                next_states = tf.convert_to_tensor(np.array(next_states), dtype=tf.float32)\n",
    "                dones = tf.convert_to_tensor(np.array(dones, dtype=np.float32), dtype=tf.float32)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    q_values = q_estimator(states)\n",
    "                    q_values = tf.gather(q_values, actions, batch_dims=1)\n",
    "\n",
    "                    next_q_values = target_estimator(next_states)\n",
    "                    max_next_q_values = tf.reduce_max(next_q_values, axis=1)\n",
    "                    targets = rewards + discount_factor * max_next_q_values * (1 - dones)\n",
    "                    \n",
    "                    loss = tf.keras.losses.MSE(targets, q_values)\n",
    "\n",
    "                grads = tape.gradient(loss, q_estimator.trainable_variables)\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "                optimizer.apply_gradients(zip(grads, q_estimator.trainable_variables))\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            step_count += 1\n",
    "\n",
    "        rewards_list.append(total_reward)\n",
    "\n",
    "        # Update target network every few episodes\n",
    "        if episode % update_target_estimator_every == 0:\n",
    "            target_estimator.set_weights(q_estimator.get_weights())\n",
    "\n",
    "        # Save model checkpoint\n",
    "        q_estimator.save_weights(checkpoint_path)\n",
    "\n",
    "        print(f\"Episode {episode+1}, Reward: {total_reward}, Epsilon: {epsilon:.4f}\")\n",
    "\n",
    "    return rewards_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.int64(200063628): 0, np.int64(200063636): 1, np.int64(200063644): 2, np.int64(200063815): 3, np.int64(200063818): 4, np.int64(200063864): 5, np.int64(200063865): 6, np.int64(200063963): 7, np.int64(200063985): 8, np.int64(200064227): 9, np.int64(200064292): 10, np.int64(200064317): 11, np.int64(200064321): 12, np.int64(200064324): 13, np.int64(200064337): 14, np.int64(200064488): 15, np.int64(200064533): 16, np.int64(200064538): 17, np.int64(200064539): 18, np.int64(200064540): 19, np.int64(200064548): 20, np.int64(200064582): 21, np.int64(200064693): 22, np.int64(200064912): 23, np.int64(200064913): 24, np.int64(200065239): 25, np.int64(200066402): 26, np.int64(200067147): 27, np.int64(200067454): 28, np.int64(200069656): 29, np.int64(200069897): 30, np.int64(200069928): 31, np.int64(200070013): 32, np.int64(200070023): 33, np.int64(200070075): 34, np.int64(200072406): 35, np.int64(200072409): 36, np.int64(200072418): 37, np.int64(200072450): 38, np.int64(200072491): 39, np.int64(200076556): 40, np.int64(200076557): 41, np.int64(200076558): 42, np.int64(200076569): 43, np.int64(200076574): 44, np.int64(200076575): 45, np.int64(200076634): 46, np.int64(200076722): 47, np.int64(200076780): 48, np.int64(200076856): 49, np.int64(200076859): 50, np.int64(200076860): 51, np.int64(200076862): 52, np.int64(200076868): 53, np.int64(200076869): 54, np.int64(200076885): 55, np.int64(200079542): 56, np.int64(200079548): 57, np.int64(200079571): 58, np.int64(200079603): 59, np.int64(200079614): 60, np.int64(200079631): 61, np.int64(200079638): 62, np.int64(200079640): 63, np.int64(200079643): 64, np.int64(200079681): 65, np.int64(200079682): 66, np.int64(200079687): 67, np.int64(200079696): 68, np.int64(200079697): 69, np.int64(200079698): 70, np.int64(200079966): 71, np.int64(200079969): 72, np.int64(200080252): 73, np.int64(200080255): 74, np.int64(200080256): 75, np.int64(200080257): 76, np.int64(200080259): 77, np.int64(200080261): 78, np.int64(200080267): 79, np.int64(200080270): 80, np.int64(200080274): 81, np.int64(200076956): 82, np.int64(200076959): 83, np.int64(200076960): 84, np.int64(200076961): 85, np.int64(200076962): 86, np.int64(200076963): 87, np.int64(200076964): 88, np.int64(200076965): 89, np.int64(210070597): 90, np.int64(210070634): 91, np.int64(210070635): 92, np.int64(210070637): 93, np.int64(210070638): 94, np.int64(210070645): 95, np.int64(210070647): 96, np.int64(210070648): 97, np.int64(210070654): 98, np.int64(210070707): 99, np.int64(210070708): 100, np.int64(210070718): 101, np.int64(210076143): 102, np.int64(210076190): 103, np.int64(210076198): 104, np.int64(210077223): 105, np.int64(210077224): 106, np.int64(210077225): 107, np.int64(210077226): 108, np.int64(210077227): 109, np.int64(210077228): 110, np.int64(210077229): 111, np.int64(210077230): 112, np.int64(210077231): 113, np.int64(210077232): 114, np.int64(210077247): 115, np.int64(210077294): 116, np.int64(210077298): 117, np.int64(210077299): 118, np.int64(210077322): 119, np.int64(210077314): 120, np.int64(210077323): 121, np.int64(210077332): 122, np.int64(210077334): 123, np.int64(210077351): 124, np.int64(210077376): 125, np.int64(210077381): 126, np.int64(210077389): 127, np.int64(210077398): 128, np.int64(210077407): 129, np.int64(210077408): 130, np.int64(210077411): 131, np.int64(210070729): 132, np.int64(210070781): 133, np.int64(210071089): 134, np.int64(210071124): 135, np.int64(210071180): 136, np.int64(210071182): 137, np.int64(210071183): 138, np.int64(210071185): 139, np.int64(210071186): 140, np.int64(210071586): 141, np.int64(210071599): 142, np.int64(210071610): 143, np.int64(210071636): 144, np.int64(210071637): 145, np.int64(210071668): 146, np.int64(210071643): 147, np.int64(210071644): 148, np.int64(210071653): 149, np.int64(210071670): 150, np.int64(210071674): 151, np.int64(210071710): 152, np.int64(210071801): 153, np.int64(210071919): 154, np.int64(210072080): 155, np.int64(210072120): 156, np.int64(210072121): 157, np.int64(210072132): 158, np.int64(210072122): 159, np.int64(210072123): 160, np.int64(210072131): 161, np.int64(210072135): 162, np.int64(210072136): 163, np.int64(210072137): 164, np.int64(210072140): 165, np.int64(210072162): 166, np.int64(210072164): 167, np.int64(210072168): 168, np.int64(210072200): 169, np.int64(210072204): 170, np.int64(210072233): 171, np.int64(210072266): 172, np.int64(210072640): 173, np.int64(210072647): 174, np.int64(210072648): 175, np.int64(210072649): 176, np.int64(210072827): 177, np.int64(210073059): 178, np.int64(210073073): 179, np.int64(210073078): 180, np.int64(210073091): 181, np.int64(210073092): 182, np.int64(210073118): 183, np.int64(210073119): 184, np.int64(210073120): 185, np.int64(210073128): 186, np.int64(210073129): 187, np.int64(210073259): 188, np.int64(210073273): 189, np.int64(210073632): 190, np.int64(210074148): 191, np.int64(210074150): 192, np.int64(210074151): 193, np.int64(210074200): 194, np.int64(210074219): 195, np.int64(210074340): 196, np.int64(210074486): 197, np.int64(210074487): 198, np.int64(210074488): 199, np.int64(210074492): 200, np.int64(210074493): 201, np.int64(210074494): 202, np.int64(210074501): 203, np.int64(210074519): 204, np.int64(210074523): 205, np.int64(210074539): 206, np.int64(210067722): 207, np.int64(210067653): 208, np.int64(210067748): 209, np.int64(210067753): 210, np.int64(210067766): 211, np.int64(210067781): 212, np.int64(210067809): 213, np.int64(210067850): 214, np.int64(210067851): 215, np.int64(210067890): 216, np.int64(210068091): 217, np.int64(210068669): 218, np.int64(210068799): 219, np.int64(210068770): 220, np.int64(210068791): 221, np.int64(210068795): 222, np.int64(210068800): 223, np.int64(210068802): 224, np.int64(210068804): 225, np.int64(210068806): 226, np.int64(210068807): 227, np.int64(210068808): 228, np.int64(210068812): 229, np.int64(210068874): 230, np.int64(210068880): 231, np.int64(210068881): 232, np.int64(210068925): 233, np.int64(210068927): 234, np.int64(210068928): 235, np.int64(210068949): 236, np.int64(210069069): 237, np.int64(210069108): 238, np.int64(210069492): 239, np.int64(210069605): 240, np.int64(210069664): 241, np.int64(210069999): 242, np.int64(210070073): 243, np.int64(210070241): 244, np.int64(400065843): 245, np.int64(400065844): 246, np.int64(210072889): 247, np.int64(200076266): 248, np.int64(210070502): 249, np.int64(210070567): 250, np.int64(210070591): 251, np.int64(210077295): 252, np.int64(210071184): 253, np.int64(210071792): 254, np.int64(210072646): 255, np.int64(210073629): 256, np.int64(210074149): 257, np.int64(210074546): 258, np.int64(210075084): 259, np.int64(210075986): 260, np.int64(200080786): 261, np.int64(200080792): 262, np.int64(200082459): 263, np.int64(210047092): 264, np.int64(210047112): 265, np.int64(210048754): 266, np.int64(210063778): 267, np.int64(210063767): 268, np.int64(210063774): 269, np.int64(210063787): 270, np.int64(210066196): 271, np.int64(210066580): 272, np.int64(210066587): 273, np.int64(210066848): 274, np.int64(210067759): 275, np.int64(210067849): 276, np.int64(210068805): 277, np.int64(210068859): 278, np.int64(210068882): 279, np.int64(210069130): 280, np.int64(200059765): 281, np.int64(200059969): 282, np.int64(200060223): 283, np.int64(200072741): 284, np.int64(200072977): 285, np.int64(200074679): 286, np.int64(200074755): 287, np.int64(200060957): 288, np.int64(200062878): 289, np.int64(200063042): 290, np.int64(200063981): 291, np.int64(200064138): 292, np.int64(200072298): 293, np.int64(200052137): 294, np.int64(200052151): 295, np.int64(200053011): 296, np.int64(200058219): 297, np.int64(200056815): 298, np.int64(200076508): 299, np.int64(200076857): 300, np.int64(200079724): 301, np.int64(200079888): 302, np.int64(200080264): 303, np.int64(200080272): 304, np.int64(200080471): 305, np.int64(200077422): 306, np.int64(200077439): 307, np.int64(200078945): 308, np.int64(200079021): 309, np.int64(200079399): 310, np.int64(200079482): 311, np.int64(200079510): 312, np.int64(210077815): 313, np.int64(210078112): 314, np.int64(400059043): 315, np.int64(400066476): 316, np.int64(200064136): 317, np.int64(210077626): 318, np.int64(210077627): 319, np.int64(210077628): 320, np.int64(210077666): 321, np.int64(210077671): 322, np.int64(210077741): 323, np.int64(210077773): 324, np.int64(210077846): 325, np.int64(210077945): 326, np.int64(210077949): 327, np.int64(210078085): 328, np.int64(210078136): 329, np.int64(210078139): 330, np.int64(210078154): 331, np.int64(210078399): 332, np.int64(210078390): 333, np.int64(210078396): 334, np.int64(210078398): 335, np.int64(210078900): 336, np.int64(210078912): 337, np.int64(210078918): 338, np.int64(210078926): 339, np.int64(210078934): 340, np.int64(210078936): 341, np.int64(210079172): 342, np.int64(210079173): 343, np.int64(210079444): 344, np.int64(210079578): 345, np.int64(400055883): 346, np.int64(400056084): 347, np.int64(400058119): 348, np.int64(400059031): 349, np.int64(400059032): 350, np.int64(400059033): 351, np.int64(400059034): 352, np.int64(400059039): 353, np.int64(400059042): 354, np.int64(400066298): 355, np.int64(400065936): 356, np.int64(400066431): 357, np.int64(200058332): 358, np.int64(200058328): 359, np.int64(200058329): 360, np.int64(200058331): 361, np.int64(200058335): 362, np.int64(200058336): 363, np.int64(200058341): 364, np.int64(200058348): 365, np.int64(200058474): 366, np.int64(200058486): 367, np.int64(200058607): 368, np.int64(200058967): 369, np.int64(200059095): 370, np.int64(200059968): 371, np.int64(200059970): 372, np.int64(200060221): 373, np.int64(200060231): 374, np.int64(200060272): 375, np.int64(200060401): 376, np.int64(200060402): 377, np.int64(200060433): 378, np.int64(200060579): 379, np.int64(200060580): 380, np.int64(200072583): 381, np.int64(200072595): 382, np.int64(200072599): 383, np.int64(200072600): 384, np.int64(200072738): 385, np.int64(200072739): 386, np.int64(200072740): 387, np.int64(200072742): 388, np.int64(200072967): 389, np.int64(200072911): 390, np.int64(200072969): 391, np.int64(200072978): 392, np.int64(200072998): 393, np.int64(200073387): 394, np.int64(200073399): 395, np.int64(200073472): 396, np.int64(200073478): 397, np.int64(200073712): 398, np.int64(200074219): 399, np.int64(200074303): 400, np.int64(200074678): 401, np.int64(200074680): 402, np.int64(200074682): 403, np.int64(200074756): 404, np.int64(200074825): 405, np.int64(200074847): 406, np.int64(200074857): 407, np.int64(200075494): 408, np.int64(200075495): 409, np.int64(200075497): 410, np.int64(200060588): 411, np.int64(200060597): 412, np.int64(200060690): 413, np.int64(200060809): 414, np.int64(200060872): 415, np.int64(200060972): 416, np.int64(200061136): 417, np.int64(200061181): 418, np.int64(200061196): 419, np.int64(200061201): 420, np.int64(200062879): 421, np.int64(200062880): 422, np.int64(200063177): 423, np.int64(200063199): 424, np.int64(200063536): 425, np.int64(200042963): 426, np.int64(200042964): 427, np.int64(200042967): 428, np.int64(200047325): 429, np.int64(200050059): 430, np.int64(200050939): 431, np.int64(200052150): 432, np.int64(200052152): 433, np.int64(200052153): 434, np.int64(200052653): 435, np.int64(200053006): 436, np.int64(200053009): 437, np.int64(200053014): 438, np.int64(200053023): 439, np.int64(200053127): 440, np.int64(200053128): 441, np.int64(200053131): 442, np.int64(200053132): 443, np.int64(200054169): 444, np.int64(200054171): 445, np.int64(200054173): 446, np.int64(200054573): 447, np.int64(200056258): 448, np.int64(200056623): 449, np.int64(200056624): 450, np.int64(200056740): 451, np.int64(200056741): 452, np.int64(200056743): 453, np.int64(200058195): 454, np.int64(200058196): 455, np.int64(200058290): 456, np.int64(200058324): 457, np.int64(200058325): 458, np.int64(200058327): 459, np.int64(200077108): 460, np.int64(200077159): 461, np.int64(200077168): 462, np.int64(200077179): 463, np.int64(200077332): 464, np.int64(200077421): 465, np.int64(200077423): 466, np.int64(200077425): 467, np.int64(200077454): 468, np.int64(200077457): 469, np.int64(200077458): 470, np.int64(200077461): 471, np.int64(200077464): 472, np.int64(200077887): 473, np.int64(200077911): 474, np.int64(200077944): 475, np.int64(200077958): 476, np.int64(200078152): 477, np.int64(200078924): 478, np.int64(200078930): 479, np.int64(200078932): 480, np.int64(200078938): 481, np.int64(200078941): 482, np.int64(200078943): 483, np.int64(200078947): 484, np.int64(200078948): 485, np.int64(200079020): 486, np.int64(200079032): 487, np.int64(200079424): 488, np.int64(200079500): 489, np.int64(200079501): 490, np.int64(200075567): 491, np.int64(200079503): 492, np.int64(200079527): 493, np.int64(200075566): 494, np.int64(200075568): 495, np.int64(200075580): 496, np.int64(200075920): 497, np.int64(200075963): 498, np.int64(200075984): 499, np.int64(200076063): 500, np.int64(200076194): 501, np.int64(200076160): 502, np.int64(200076227): 503, np.int64(200076255): 504, np.int64(200076257): 505, np.int64(200076273): 506, np.int64(200076323): 507, np.int64(200076346): 508, np.int64(200076347): 509, np.int64(200076348): 510, np.int64(200076406): 511, np.int64(210070503): 512, np.int64(210070550): 513, np.int64(210070564): 514, np.int64(210070568): 515, np.int64(210070592): 516, np.int64(210070593): 517, np.int64(210070594): 518, np.int64(210070595): 519, np.int64(210070596): 520, np.int64(210074671): 521, np.int64(210074692): 522, np.int64(210074714): 523, np.int64(210074930): 524, np.int64(210074932): 525, np.int64(210074935): 526, np.int64(210075070): 527, np.int64(210075250): 528, np.int64(210075257): 529, np.int64(210075260): 530, np.int64(210075526): 531, np.int64(210075741): 532, np.int64(210075716): 533, np.int64(210075732): 534, np.int64(210075745): 535, np.int64(210075788): 536, np.int64(210075789): 537, np.int64(210075798): 538, np.int64(210075959): 539, np.int64(210075988): 540, np.int64(210076068): 541, np.int64(210076069): 542, np.int64(210076070): 543, np.int64(210076071): 544, np.int64(210076091): 545, np.int64(210076133): 546, np.int64(200080478): 547, np.int64(200080567): 548, np.int64(200080741): 549, np.int64(200080789): 550, np.int64(200080790): 551, np.int64(200080791): 552, np.int64(200080793): 553, np.int64(200080794): 554, np.int64(200080795): 555, np.int64(200080796): 556, np.int64(200081314): 557, np.int64(200081315): 558, np.int64(200081418): 559, np.int64(200081421): 560, np.int64(200081889): 561, np.int64(200081873): 562, np.int64(200081874): 563, np.int64(200082089): 564, np.int64(200082091): 565, np.int64(200082230): 566, np.int64(200082332): 567, np.int64(200082400): 568, np.int64(210046478): 569, np.int64(210047091): 570, np.int64(210047093): 571, np.int64(210047095): 572, np.int64(210047096): 573, np.int64(210047100): 574, np.int64(210047102): 575, np.int64(210047107): 576, np.int64(210047113): 577, np.int64(210048387): 578, np.int64(210052671): 579, np.int64(210056248): 580, np.int64(210056257): 581, np.int64(210056392): 582, np.int64(210056391): 583, np.int64(210056393): 584, np.int64(210056434): 585, np.int64(210060221): 586, np.int64(210060670): 587, np.int64(210060671): 588, np.int64(210061504): 589, np.int64(210061565): 590, np.int64(210063766): 591, np.int64(210063773): 592, np.int64(210063775): 593, np.int64(210063776): 594, np.int64(210063777): 595, np.int64(210063783): 596, np.int64(210063786): 597, np.int64(210063791): 598, np.int64(210064998): 599, np.int64(210065148): 600, np.int64(210065150): 601, np.int64(210065153): 602, np.int64(210065165): 603, np.int64(210065166): 604, np.int64(210065182): 605, np.int64(210065192): 606, np.int64(210065194): 607, np.int64(210065207): 608, np.int64(210065209): 609, np.int64(210065235): 610, np.int64(210065236): 611, np.int64(210066194): 612, np.int64(210066567): 613, np.int64(210066389): 614, np.int64(210066557): 615, np.int64(210066566): 616, np.int64(210066579): 617, np.int64(210066581): 618, np.int64(210066582): 619, np.int64(210066585): 620, np.int64(210066588): 621, np.int64(210066846): 622, np.int64(210066847): 623, np.int64(210067101): 624, np.int64(210067410): 625}\n"
     ]
    }
   ],
   "source": [
    "experiment_dir = \"./experiments\"\n",
    "\n",
    "checkpoint_path = os.path.join(experiment_dir, 'checkpoints', \"model.weights.h5\")\n",
    "\n",
    "# Initialize environment and state processor\n",
    "env = AnaquelEnv(df)\n",
    "state_processor = StateProcessor(env)\n",
    "\n",
    "# Get input and output dimensions\n",
    "num_products = env.num_products\n",
    "input_dim = (env.rows * env.cols) * (1 + num_products)\n",
    "output_dim = env.action_space\n",
    "\n",
    "# Create Q-networks (online & target)\n",
    "q_network = QNetwork(input_dim, output_dim)\n",
    "target_q_network = QNetwork(input_dim, output_dim)\n",
    "target_q_network.set_weights(q_network.get_weights())  # Sync weights initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741315072.578211  567930 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13666 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Loading saved weights...\")\n",
    "    dummy_input = tf.random.uniform((1, input_dim))  # Create dummy input\n",
    "    q_network(dummy_input)  # Forward pass to initialize model\n",
    "    target_q_network(dummy_input)\n",
    "\n",
    "    # Now load weights\n",
    "    q_network.load_weights(checkpoint_path)\n",
    "    target_q_network.load_weights(checkpoint_path)\n",
    "else:\n",
    "    print(\"No saved model found! Train the model first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating replay memory...\n",
      "Replay memory initialized.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rewards_list \u001b[38;5;241m=\u001b[39m \u001b[43mdeep_q_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_q_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 97\u001b[0m, in \u001b[0;36mdeep_q_learning\u001b[0;34m(sess, env, q_estimator, target_estimator, state_processor, num_episodes, experiment_dir, replay_memory_size, replay_memory_init_size, update_target_estimator_every, discount_factor, epsilon_start, epsilon_end, epsilon_decay_steps, batch_size)\u001b[0m\n\u001b[1;32m     95\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, q_estimator\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     96\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m    100\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:383\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    382\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterations\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:448\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    445\u001b[0m     grads \u001b[38;5;241m=\u001b[39m [g \u001b[38;5;28;01mif\u001b[39;00m g \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m g \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:511\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# Run update step.\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend_update_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables\n\u001b[1;32m    518\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:120\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[1;32m    119\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_reduce_sum_gradients(grads_and_vars)\n\u001b[0;32m--> 120\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_tf_update_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:134\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 134\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:131\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad, learning_rate):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/optimizers/adam.py:117\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mupdate_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, gradient, variable, learning_rate):\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update step given gradient and the associated model variable.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     lr \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(gradient, variable\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    119\u001b[0m     local_step \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, variable\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/ops/core.py:803\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x,)):\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Cast(dtype\u001b[38;5;241m=\u001b[39mdtype)(x)\n\u001b[0;32m--> 803\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:201\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py:1012\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m   1006\u001b[0m   x \u001b[38;5;241m=\u001b[39m indexed_slices\u001b[38;5;241m.\u001b[39mIndexedSlices(values_cast, x\u001b[38;5;241m.\u001b[39mindices, x\u001b[38;5;241m.\u001b[39mdense_shape)\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1008\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_complex \u001b[38;5;129;01mand\u001b[39;00m base_type\u001b[38;5;241m.\u001b[39mis_floating:\n\u001b[1;32m   1014\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.  This will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscard the imaginary part and may not be what you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintended.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTEC/Belcorp/test2/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:717\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpack_eager_tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, [packed_tensor], tensors,\n\u001b[1;32m    712\u001b[0m                           grad_fun)\n\u001b[1;32m    714\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m packed_tensor\n\u001b[0;32m--> 717\u001b[0m \u001b[38;5;129m@profiler_trace\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_wrapper(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert_to_tensor\u001b[39m(\n\u001b[1;32m    719\u001b[0m     value,\n\u001b[1;32m    720\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    721\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    722\u001b[0m     as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    723\u001b[0m     preferred_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    724\u001b[0m     dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;66;03m# TODO(b/268347915): Remove argument.\u001b[39;00m\n\u001b[1;32m    726\u001b[0m     ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m    727\u001b[0m     accepted_result_types\u001b[38;5;241m=\u001b[39m(tensor_lib\u001b[38;5;241m.\u001b[39mTensor,),\n\u001b[1;32m    728\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[EagerTensor, SymbolicTensor]:\n\u001b[1;32m    729\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Implementation of the public convert_to_tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m    730\u001b[0m   \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "rewards_list = deep_q_learning(None, env, q_network, target_q_network, state_processor, num_episodes=500, experiment_dir=experiment_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trained_model(env, q_network, state_processor, num_episodes=10):\n",
    "    \"\"\"\n",
    "    Runs the trained agent in the environment without exploration (ε = 0).\n",
    "\n",
    "    Args:\n",
    "        env: The environment to test in.\n",
    "        q_network: The trained Q-Network.\n",
    "        state_processor: Processes environment states into model-compatible format.\n",
    "        num_episodes: Number of episodes to test.\n",
    "\n",
    "    Returns:\n",
    "        A list of total rewards for each episode.\n",
    "    \"\"\"\n",
    "    total_rewards = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state_quantities, state_products_onehot = env.reset()\n",
    "        state = state_processor.process(state_quantities, state_products_onehot)\n",
    "\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "\n",
    "        while not done:\n",
    "            # Get action from trained model (greedy policy, no exploration)\n",
    "            q_values = q_network(tf.expand_dims(state, axis=0))[0].numpy()\n",
    "            action = np.argmax(q_values)  # Choose best action\n",
    "\n",
    "            # Convert action index to (zone, anaquel, row, col)\n",
    "            zone, anaquel, row, col = np.unravel_index(action, (env.zones, env.anaqueles_per_zone, env.rows, env.cols))\n",
    "\n",
    "            # Take step in the environment\n",
    "            next_state_quantities, next_state_products_onehot, reward, done = env.step((zone, anaquel, row, col))\n",
    "            next_state = state_processor.process(next_state_quantities, next_state_products_onehot)\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            step_count += 1\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "        print(f\"Test Episode {episode+1}: Total Reward = {total_reward}\")\n",
    "\n",
    "    return total_rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rewards = test_trained_model(env, q_network, state_processor, num_episodes=10)\n",
    "print(\"Average Reward over 10 Episodes:\", np.mean(test_rewards))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
